# DIY Baby Monitoring with Open Source Tech

**Transcribed:** 11 Dec 2025
**Backend:** Gemini 2.0 Flash
**Type:** Cleaned (edited for readability)

---

Alright, so I thought I'd just record a few notes in this repository as the year is coming to a close regarding different things I figured out for baby monitoring at home and different systems in case this might help any other parents who happen to be on GitHub and into open source tech.

I want to say that none of this is in any way arguing against commercial solutions for baby monitoring. My wife and I certainly looked at those, and I guess we're using them, but it's just kind of patching it into existing systems that I want to talk about, like Home Assistant, etc.

So, and I also want to make a few notes about hardware just in terms of what's feasible, because I think sometimes what appears to be kind of easy is actually turns out to be quite complicated but for reasons that are probably avoidable if you are someone who is prepared to invest in, let's say, a dedicated home piece of hardware optimized for stuff like object recognition, which would be, to my mind at least, probably what I would have done in a in a in the best-case scenario.

## Video Monitoring

Okay, for video monitoring, just a couple of notes. So we had a few IP cameras around the house for home security when we were away—the Tapo C210. When we had Ezra—Ezra is about five months old for context at the time I'm recording this—I noticed the nighttime performance was really, really poor. So I got onto chat GPT and recommended Reolink, and I have a really strong and totally unbiased recommendation for them. I picked up an E1 Pro, which has Ethernet, which is very recommended, and absolutely a stellar piece of hardware. The clarity is brilliant in terms of what you can see. When Ezra was sleeping in our bedroom, the room would be completely pitch dark that I couldn't see him, but I could just open up my phone and, in the Reolink app or Home Assistant, could very clearly see that he was okay.

That was how we got into it the first night that he was sleeping very deeply. We were like, "Oh my gosh, it's kind of a bit—we can't tell if he's moving, God forbid." So, that changed our mind to the advantage of doing some kind of monitoring.

So these really the kind of I'd say the pain points. So we set up a few different cameras based on where Ezra is during the day so we can, if there's any time where either of us aren't—my wife and I aren't—in proximity, that we at least have the camera there that we can kind of keep an eye on him, even if it assists for a few minutes. One thing to think about, I guess, is the wifi overhead, which is why, again, there's kind of best-case scenario—best case—what I would do if money wasn't a constraint and what I'm doing in practice: if money was not a constraint, I would have nothing on wifi at all because even putting two cameras on the network, you're at that 2.4 gigahertz band, especially if you've got Zigbee stuff, you're going to quickly get a lot of congestion.

And it's a problem that can be avoided very easily by putting the cameras on power over Ethernet. So Reolink, great manufacturer depending where you are in the world, there might be other ones, but that's my—that would be my recommendation there—to keep it on, to keep all the, keep all IP camera stuff on Ethernet.

## Streaming Setup

So then, for—so that's kind of the system that I did was used web RTC, which I find really excellent to restreamer. So basically, because we had a mixture, because we have a mixture of TP-Link and Reolink, practically speaking, it's a pain in the backside to be juggling these kind of apps for, you know, for just trying to get a unified camera feed. So the first thing, both of these apps, and my sort of hard criteria for picking up cameras is that they support RTSP. If you can get an RTSP stream out of the camera, you can integrate it usually with anything. PTZ is another bit of an issue, but RTSP friendly. So both TP-Link and Reolink haven't had an issue there.

And getting those feeds in, I initially tried Frigate (FRIGATE), which is really a terrific app, but I'm running my home server is basically my old desktop. It's running an i3, and it's got an Nvidia 1050 GPU, and basically object detection—the more cameras, the more workload you're going to have, and it was, to be honest, really challenging to, with Frigate. I kept having to disable things in order to avoid getting it to do what I really wanted to do, which was doing GPU detection.

And ultimately, I spent a lot of time trying to get Nvidia to work with it because it's an older GPU, didn't work. Tried building object recognition models, then eventually said, "I really don't have that much time for this." I tried scripted as well (SCRYPTED), which is a very nice platform, but ultimately, for, you know, trying to do this on legacy hardware, I actually had the best results by far just using a restreamer—web RTC. Advantages are a few advantages. One is that if you have different manufacturers, even if the only advantage is you're restreaming in a consistent video and audio codec, that's actually still quite useful. And then you can build your front end to that. So that layer has been surprisingly robust, and the overhead, the computational overhead of even doing a little bit of audio codec restreaming has been actually remarkably small. So object recognition, I quickly discovered it wasn't a non-runner for me.

There is something called the Coral TPU from Google, Tensor Processing Unit, that is really popular with Frigate, and I could not find a TPU just in my locality at all. So it wasn't something I could find on the markets, but if you can get one of those, I guess that kind of makes a lot of sense for making Frigate work.

The other thing that's really useful is that you can add to a stack is MQTT, of course. And the other thing I would say from my experience doing this is object recognition. I kind of thought this is a good, this is a chance to learn a bit about computer vision and machine learning. So using a stuffed animal, I created a little model for, you know, what we would be worried about, which was, let's say, that our son experimented with non-motion recognition, and with stuff like pulling a blanket over their face—the stuffed animal, as in that would be the warning condition, let's say.

Eventually, just didn't really—those approaches it's really tricky; you're going to get, as soon as you get into false positives, the system is going to create more stress than it solves. And what I ultimately actually found the best success with was simple facial recognition—not—and that sounds very creepy because we're talking about a newborn, but not actually recognizing his specific face, but in auto-cropping script that I added, which basically says if there's a face in the frame, that's the active camera, and we're going to crop in a little bit on the face. So that's actually quite easy to integrate, and it just means you can have a little monitor if you're working at night, I'm a big night owl, and wherever that your newborn is detected, that will be Boolean positive and it'll crop a little bit. And then I find that just there's no technology that can substitute for just seeing, you know, that everything's okay, and then periodically going in to check on him. When he was waking up at nighttime, we'd kind of see if he was putting himself back to sleep or needed to get back up. So both my wife and I have found it a really invaluable asset actually.

## Audio Monitoring

Then for cry detection, audio, audio object detection is actually easier—a lot easier—than video, in the sense that you can run it on a CPU at a push. And there's two things really, if you're like, if you're trying, if you're trying to get cry notifications—in our case, I keep trying to, you know, not create technological solutions that are like no better than just using your ears. So for cry detection, you can—there are some data sets that will have that cry object, but if there's—if there's—if you're just trying to—in our case, let's say our son Ezra is in a quiet room, and it's just easier to do volume detection. Whether that counts as a cry or a coo or a scream, the risk with doing, trying to be too smart with sound detection is exactly that; you're going to, it's going to classify audio events incorrectly. So the most blunt form way to do it is just to volume-based detection and just, you know, record a few seconds, wait for your baby to cry, measure the decibels, and set that as your threshold for triggering an alert if you want to go down that route.

And MQTT and Home Assistant, all this can be done very easily. You can write a script that if the audio passes this level. And then for baby—for cry monitoring, so my wife bought a little monitor, and we actually ended up using a home system—a home, a DIY system ended up actually being just as useful. And the system I use is as follows: if you have a Reolink or a TP-Link camera, it's probably putting out an audio stream. So I highly recommend just using Claude or Chat GPT to do all the hard work and say, "Hey, this is the IP address." And I should have included that in my notes here. Highly, very important, assign fixed IP addresses for your cameras so stuff isn't moving around unpredictably. So you can say, "Can you tell me what audio codec and what—what the audio is streaming at?" And once you've identified that, in web RTC you can have an audio only restream. But I actually found it more effective to do an Icecast server. It's pretty old tech, but the issue with having stuff like ffmpeg streaming it like that is that if the client drops, the stream might drop. So putting an Icecast server means that the stream's always good, and you can even do a little bit of down sampling. So you might find that the camera puts out, the audio feed is actually unnecessarily heavy in terms of the bit rate, and you can actually have an Icecast server, just get it down to the bare minimum that you can hear audio events clearly. It doesn't need to be beautiful quality audio, and then what I—what we do in practice is using VLC on our phone. You can just bookmark the Icecast server MP3 stream, save that, and then just have your phone open overnight. Leave it on, leave it running in the background, test that it works, and it's basically a DIY cry monitor. You'll hear it comes through very clearly. We also did it to a speaker in our bedroom, and that was a little bit too noisy. Phone—the phone system works really, really well. It's fast, it's over the local network. It's a lightweight audio server, streaming audio. You can just open that on your phone or whatever you want to use, and you won't miss that. I think it works more effectively and reliably than the thing that my wife bought, but then again, I would say that.

## Summary and Key Takeaways

So those are my notes so far. I hope that is helpful to someone maybe, and I'll use our friendly AI tool to summarize and gather together the information. I think the main thing I've learned really is from the start, it's just about a few little—it's about kind of common sense tech as in getting a reliable way to watch a video stream, and getting a reliable way to hear if they're crying than trying to go, go too complex and AI detection and vision. I just found it was computationally too much, and you—it's just about getting up to something that's actually usable and valuable. In Home Assistant, advanced camera card is a great app for folks who don't have PTZ cameras. My ones aren't PTZ, and you can do digital zoom on that, which is actually quite neglected in IP camera viewers, because I think most of them are built for proper sort of surveillance systems where everything has PTZ, but if your cameras don't, the Reolink and the Tapo-Link have—it's it is tilt and pan technically. It doesn't have true optical zoom, that's controllable, whether through the app or through a third party.

That's something I had to actually build into a little front-end monitoring GUI that I created. And in terms of two-way audio and pan and zoom control, it's kind of hit and miss to be honest. There is like ONVIF protocol, and there are on GitHub unofficial API wrappers for the cameras, but it's a bit tricky to get that working, but in theory, you should be able to control a camera and add that functionality into any external tool as well, but it really depends on a camera by camera basis. If you're building, if you're picking out gear or hardware for this purpose, with the idea of integrating it into an existing smart home, I think as always probably the best bet is to go on Reddit, you know, and GitHub and see what people recommend as the most flexible manufacturer for allowing you to actually sort of use what you pay for.

## Privacy Considerations

The other concern I had with IP cameras is just getting like data leaving the network, and I think I did a pretty decent audit to make sure the cameras disable the cloud, but that's something again that in the best case scenario, I would actually look for tech that doesn't have, if that's a concern for you for privacy, no cloud hooking whatsoever, and you really, the only way—I think that's the only way to be relatively certain that your camera feeds are going where you hope they are and not somewhere else, is to not have any of these kind of convenience features from the manufacturers. And then for streaming it out of the network, Tailscale is a brilliant tool, is a fantastic tool because you can just have it on your phone, connect to your tail net, and then just use the, put in the IP address, and IP Camera Pro for Android is a terrific app as well. So that combination will allow you to remotely monitor, and then you don't need to do any of the Tailscale stuff. And then for local viewing, gosh, that's a lot of information that I realized I've kind of picked up about this. MSE is a really decent protocol, you'll get very good speed, but the name—the golden rule—is that for low latency monitoring at home, RTSP and web RTC will restream RTSP as well as the other protocol. So it really gives you all the options for however you want to consume and aggregate your streams, and you can even do something like you can even do kind of just, if you have more underlying computation to work with on the device you're doing the restreaming, you can absolutely restream a cropped in stream, restream it with some video, you know, editing the saturation, all that stuff is possible. So it's actually, I would say, one of the most helpful components.

## Recommended Stack

So my stack that I recommend, or the stack that I—that is—the stellar options for me would be, I would say:

- **RTSP**
- **WebRTC**
- **MQTT**
- **Icecast**
- **Home Assistant**

And with those components, you can kind of do pretty much everything.
